# ğŸ¤– Machine Learning from Data - Repository Guide

<div align="center">

![Machine Learning](https://img.shields.io/badge/Machine%20Learning-CS3141-blue?style=for-the-badge)
![University](https://img.shields.io/badge/Reichman%20University-2025-orange?style=for-the-badge)
![Status](https://img.shields.io/badge/Repository-Active-green?style=for-the-badge)

*Complete implementation and study materials for machine learning algorithms and techniques*

**Instructors:** Prof. Ilan Gronau & Dr. Alon Kipnis

</div>

---

## ğŸ“ Repository Structure

This repository contains comprehensive implementations, examples, and study materials for machine learning concepts. Each major topic is organized into dedicated folders with detailed implementations and explanations.

```
ğŸ“¦ Machine-Learning-From-Data/
â”œâ”€â”€ ğŸ“ SupervisedLearning/          # Labeled data learning algorithms
â”œâ”€â”€ ğŸ“ UnsupervisedLearning/        # Pattern discovery without labels  
â”œâ”€â”€ ğŸ“ Optimization/                # Mathematical optimization techniques
â”œâ”€â”€ ğŸ“„ SUMMARY.md                   # Course recap and quick reference
â”œâ”€â”€ ğŸ“„ README.md                    # This navigation guide
â””â”€â”€ ğŸ“„ .gitignore                   # Git ignore configurations
```

---

## ğŸ¯ SupervisedLearning/

**What you'll find:** Complete implementations of algorithms that learn from input-output pairs.

### ğŸ“‚ Folder Structure:
```
SupervisedLearning/
â”œâ”€â”€ ğŸ“ KNearestNeighbors/          # Instance-based learning
â”œâ”€â”€ ğŸ“ RegressionModels/           # Linear & polynomial regression
â”œâ”€â”€ ğŸ“ DecisionTrees/              # Tree-based classification
â”œâ”€â”€ ğŸ“ BayesianClassification/     # Probabilistic classifiers
â”œâ”€â”€ ğŸ“ Perceptron/                 # Linear separators
â”œâ”€â”€ ğŸ“ LogisticRegression/         # Probabilistic linear models
â”œâ”€â”€ ğŸ“ SupportVectorMachines/      # Maximum margin classifiers
â”œâ”€â”€ ğŸ“ ModelEvaluation/            # Validation & testing techniques
â””â”€â”€ ğŸ“„ README.md                   # Supervised learning overview
```

### ğŸ” What Each Subfolder Contains:
- **Implementation files** (`.py`, `.ipynb`)
- **Example datasets** and use cases
- **Theoretical explanations** with mathematical foundations
- **Hyperparameter tuning** guides
- **Comparative analysis** between methods

---

## ğŸ” UnsupervisedLearning/

**What you'll find:** Algorithms for discovering hidden patterns and structures in unlabeled data.

### ğŸ“‚ Folder Structure:
```
UnsupervisedLearning/
â”œâ”€â”€ ğŸ“ DistributionLearning/       # Probability distribution fitting
â”œâ”€â”€ ğŸ“ Clustering/                 # Data grouping algorithms
â”‚   â”œâ”€â”€ ğŸ“ KMeans/                 # Centroid-based clustering
â”‚   â””â”€â”€ ğŸ“ HierarchicalClustering/ # Tree-based clustering
â”œâ”€â”€ ğŸ“ ExpectationMaximization/    # EM algorithm implementations
â”œâ”€â”€ ğŸ“ DimensionalityReduction/    # PCA, LDA techniques
â””â”€â”€ ğŸ“„ README.md                   # Unsupervised learning overview
```

### ğŸ” What Each Subfolder Contains:
- **Algorithm implementations** with step-by-step explanations
- **Visualization tools** for understanding data patterns
- **Real-world datasets** for practice
- **Performance metrics** and evaluation methods
- **Interactive notebooks** for experimentation

---

## âš™ï¸ Optimization/

**What you'll find:** Mathematical optimization techniques that power machine learning algorithms.

### ğŸ“‚ Folder Structure:
```
Optimization/
â”œâ”€â”€ ğŸ“ GradientDescent/            # First-order optimization methods
â”‚   â”œâ”€â”€ ğŸ“ StandardGD/             # Batch gradient descent
â”‚   â”œâ”€â”€ ğŸ“ StochasticGD/           # SGD and mini-batch variants
â”‚   â””â”€â”€ ğŸ“ SubgradientDescent/     # Non-smooth optimization
â”œâ”€â”€ ğŸ“ LossFunctions/              # Objective functions
â”‚   â”œâ”€â”€ ğŸ“ LeastSquares/           # Regression loss
â”‚   â”œâ”€â”€ ğŸ“ CrossEntropy/           # Classification loss
â”‚   â””â”€â”€ ğŸ“ HingeLoss/              # SVM loss
â”œâ”€â”€ ğŸ“ ConstrainedOptimization/    # Lagrangian methods
â”‚   â”œâ”€â”€ ğŸ“ LagrangeMultipliers/    # Equality constraints
â”‚   â””â”€â”€ ğŸ“ DualProblems/           # Dual formulations
â””â”€â”€ ğŸ“„ README.md                   # Optimization overview
```

### ğŸ” What Each Subfolder Contains:
- **Mathematical derivations** with clear explanations
- **Implementation examples** showing convergence
- **Visualization tools** for optimization landscapes
- **Performance comparisons** between methods
- **Practical tips** for hyperparameter tuning

---

## ğŸš€ Getting Started

### Prerequisites
```bash
pip install numpy pandas matplotlib scikit-learn jupyter seaborn
```

### Quick Navigation Tips

1. **ğŸ¯ New to ML?** Start with `SupervisedLearning/KNearestNeighbors/` - it's the most intuitive
2. **ğŸ“Š Want theory?** Check each folder's `README.md` for mathematical foundations  
3. **ğŸ’» Hands-on learning?** Look for `.ipynb` files with interactive examples
4. **ğŸ”§ Implementation details?** `.py` files contain clean, documented code
5. **ğŸ“ˆ Performance insights?** `ModelEvaluation/` folder has comprehensive metrics

### Recommended Learning Path

```mermaid
graph TD
    A[Start Here] --> B[SupervisedLearning/]
    B --> C[Choose: KNN â†’ Regression â†’ Trees]
    C --> D[ModelEvaluation/]
    D --> E[UnsupervisedLearning/]
    E --> F[Optimization/]
    F --> G[Advanced Topics & Projects]
```

---

## ğŸ“– How to Use This Repository

### For Students ğŸ“š
- **Follow the learning path** above for structured progression
- **Run notebooks** to see algorithms in action
- **Modify parameters** to understand algorithm behavior
- **Compare implementations** to solidify understanding

### For Practitioners ğŸ’¼
- **Jump to specific algorithms** you need for projects
- **Use evaluation tools** for model selection
- **Adapt implementations** for your datasets
- **Reference mathematical foundations** for deeper insights

### For Researchers ğŸ”¬
- **Study optimization techniques** for algorithm development
- **Analyze theoretical foundations** in each README
- **Extend implementations** for novel approaches
- **Use visualization tools** for result presentation

---

## ğŸ› ï¸ Repository Features

- âœ… **Complete Implementations**: Every algorithm from the course
- âœ… **Interactive Examples**: Jupyter notebooks with live demonstrations  
- âœ… **Real Datasets**: Practical examples beyond toy problems
- âœ… **Visualization Tools**: Understanding through visual exploration
- âœ… **Mathematical Foundations**: Theory explained clearly
- âœ… **Performance Metrics**: Proper evaluation techniques
- âœ… **Modular Code**: Clean, reusable implementations

---

## ğŸ“‹ File Types Guide

| File Type | Purpose | When to Use |
|-----------|---------|-------------|
| `ğŸ“„ README.md` | Theory & overview | Understanding concepts |
| `ğŸ““ .ipynb` | Interactive examples | Hands-on learning |
| `ğŸ .py` | Clean implementations | Production code reference |
| `ğŸ“Š .csv/.json` | Example datasets | Testing algorithms |
| `ğŸ“ˆ .png/.svg` | Visualizations | Understanding results |

---

## ğŸ¤ Contributing

This repository is designed for learning and experimentation. Feel free to:
- ğŸ”§ Improve existing implementations
- ğŸ“Š Add new datasets or examples  
- ğŸ“ Enhance documentation
- ğŸ¨ Create better visualizations
- ğŸ§ª Add comparative studies

---

<div align="center">

### ğŸ“ Ready to Dive In?

Choose your path and start exploring! Each folder contains everything you need to master that topic.

**Remember:** The best way to learn ML is by implementing and experimenting! ğŸš€

---

![Python](https://img.shields.io/badge/Python-3.8+-blue?style=flat&logo=python)
![Jupyter](https://img.shields.io/badge/Jupyter-Notebooks-orange?style=flat&logo=jupyter)
![NumPy](https://img.shields.io/badge/NumPy-Scientific-green?style=flat&logo=numpy)
![Scikit Learn](https://img.shields.io/badge/Scikit--Learn-ML-red?style=flat&logo=scikit-learn)

</div>